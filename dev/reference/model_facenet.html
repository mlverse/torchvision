<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>MTCNN Face Detection Networks — model_facenet • torchvision</title><!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.1/jquery.min.js" integrity="sha512-v2CJ7UaYy4JwqLDIrZUI/4hqeoQieOmAZNXBeQyjo21dadnwR+8ZaIJVT8EE2iyI61OV8e6M8PP2/4hpQINQ/g==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/united/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous"><script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css"><script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous"><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet"><script src="../pkgdown.js"></script><meta property="og:title" content="MTCNN Face Detection Networks — model_facenet"><meta property="og:description" content="These models implement the three-stage Multi-task Cascaded Convolutional Networks (MTCNN)
architecture from the paper
Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks."><meta name="robots" content="noindex"><!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--><!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=G-HD24T4Z9Z3"></script><script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-HD24T4Z9Z3');
</script></head><body data-spy="scroll" data-target="#toc">


    <div class="container template-reference-topic">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">torchvision</a>
        <span class="version label label-danger" data-toggle="tooltip" data-placement="bottom" title="In-development version">0.8.0.9000</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav"><li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Examples

    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu"><li>
      <a href="../articles/examples/mnist-mlp.html">mnist-mlp</a>
    </li>
    <li>
      <a href="../articles/examples/mnist-cnn.html">mnist-cnn</a>
    </li>
    <li>
      <a href="../articles/examples/mnist-dcgan.html">mnist-dcgan</a>
    </li>
    <li>
      <a href="../articles/examples/tinyimagenet-alexnet.html">tinyimagenet-alexnet</a>
    </li>
    <li>
      <a href="../articles/examples/style-transfer.html">style-transfer</a>
    </li>
    <li>
      <a href="../articles/examples/texture-nca.html">texture-nca</a>
    </li>
  </ul></li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul><ul class="nav navbar-nav navbar-right"><li>
  <a href="https://github.com/mlverse/torchvision/" class="external-link">
    <span class="fab fa-github fa-lg"></span>

  </a>
</li>
      </ul></div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->



      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>MTCNN Face Detection Networks</h1>
    <small class="dont-index">Source: <a href="https://github.com/mlverse/torchvision/blob/main/R/models-facenet.R" class="external-link"><code>R/models-facenet.R</code></a></small>
    <div class="hidden name"><code>model_facenet.Rd</code></div>
    </div>

    <div class="ref-description">
    <p>These models implement the three-stage Multi-task Cascaded Convolutional Networks (MTCNN)
architecture from the paper
<a href="https://arxiv.org/abs/1604.02878" class="external-link">Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks</a>.</p>
    </div>

    <div id="ref-usage">
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">model_facenet_pnet</span><span class="op">(</span>pretrained <span class="op">=</span> <span class="cn">TRUE</span>, progress <span class="op">=</span> <span class="cn">FALSE</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">model_facenet_rnet</span><span class="op">(</span>pretrained <span class="op">=</span> <span class="cn">TRUE</span>, progress <span class="op">=</span> <span class="cn">FALSE</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">model_facenet_onet</span><span class="op">(</span>pretrained <span class="op">=</span> <span class="cn">TRUE</span>, progress <span class="op">=</span> <span class="cn">FALSE</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">model_mtcnn</span><span class="op">(</span>pretrained <span class="op">=</span> <span class="cn">TRUE</span>, progress <span class="op">=</span> <span class="cn">TRUE</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">model_facenet_inception_resnet_v1</span><span class="op">(</span></span>
<span>  pretrained <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  classify <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  num_classes <span class="op">=</span> <span class="fl">10</span>,</span>
<span>  dropout_prob <span class="op">=</span> <span class="fl">0.6</span>,</span>
<span>  <span class="va">...</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div id="arguments">
    <h2>Arguments</h2>


<dl><dt id="arg-pretrained">pretrained<a class="anchor" aria-label="anchor" href="#arg-pretrained"></a></dt>
<dd><p>(bool): If TRUE, returns a model pre-trained on ImageNet.</p></dd>


<dt id="arg-progress">progress<a class="anchor" aria-label="anchor" href="#arg-progress"></a></dt>
<dd><p>(bool): If TRUE, displays a progress bar of the download to
stderr.</p></dd>


<dt id="arg--">...<a class="anchor" aria-label="anchor" href="#arg--"></a></dt>
<dd><p>Other parameters passed to the model implementation.</p></dd>


<dt id="arg-classify">classify<a class="anchor" aria-label="anchor" href="#arg-classify"></a></dt>
<dd><p>Logical, whether to include the classification head. Default is FALSE.</p></dd>


<dt id="arg-num-classes">num_classes<a class="anchor" aria-label="anchor" href="#arg-num-classes"></a></dt>
<dd><p>Integer, number of output classes for classification. Default is 10.</p></dd>


<dt id="arg-dropout-prob">dropout_prob<a class="anchor" aria-label="anchor" href="#arg-dropout-prob"></a></dt>
<dd><p>Numeric, dropout probability applied before classification. Default is 0.6.</p></dd>

</dl></div>
    <div id="value">
    <h2>Value</h2>
    <p><code>model_mtcnn()</code> returns a named list with three elements:</p><ul><li><p><code>boxes</code>: A tensor of shape <code>(N, 4)</code> with bounding box coordinates <code>[x1, y1, x2, y2]</code>.</p></li>
<li><p><code>landmarks</code>: A tensor of shape <code>(N, 10)</code> with (x, y) coordinates of 5 facial landmarks:
left eye, right eye, nose, left mouth corner, right mouth corner.</p></li>
<li><p><code>cls</code>: A tensor of shape <code>(N, 2)</code> with face classification probabilities
(face / non-face). The <code>cls</code> head has two classes:</p><ul><li><p><code>1</code>: Non-face probability (background)</p></li>
<li><p><code>2</code>: Face probability — use this value for thresholding detections</p></li>
</ul></li>
</ul><p>(Here, <code>N</code> is the number of detected faces in the input image.)</p>
<p><code>model_facenet_inception_resnet_v1()</code> returns a tensor output depending on the <code>classify</code> argument:</p><ul><li><p>When <code>classify = FALSE</code> (default):
A tensor of shape <code>(N, 512)</code>, where each row is a normalized embedding
vector (L2 norm = 1).
These 512-dimensional FaceNet embeddings can be compared using cosine
similarity or Euclidean distance for face verification and clustering.</p></li>
<li><p>When <code>classify = TRUE</code>:
A tensor of shape <code>(N, num_classes)</code> containing class logits.</p></li>
</ul></div>
    <div id="details">
    <h2>Details</h2>
    <p>MTCNN detects faces and facial landmarks in an image through a coarse-to-fine pipeline:</p><ul><li><p><strong>PNet</strong> (Proposal Network): Generates candidate face bounding boxes at multiple scales.</p></li>
<li><p><strong>RNet</strong> (Refine Network): Refines candidate boxes, rejecting false positives.</p></li>
<li><p><strong>ONet</strong> (Output Network): Produces final bounding boxes and 5-point facial landmarks.</p></li>
</ul><div class="section">
<h3 id="model-variants">Model Variants<a class="anchor" aria-label="anchor" href="#model-variants"></a></h3>


<p></p><div class="sourceCode"><pre><code><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="sc">|</span> Model <span class="sc">|</span> Input Size     <span class="sc">|</span> Parameters <span class="sc">|</span> File Size <span class="sc">|</span> Outputs                       <span class="sc">|</span> Notes                             <span class="sc">|</span></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="er">|</span><span class="sc">-------</span><span class="er">|</span><span class="sc">----------------</span><span class="er">|</span><span class="sc">------------</span><span class="er">|</span><span class="sc">-----------</span><span class="er">|</span><span class="sc">-------------------------------</span><span class="er">|</span><span class="sc">-----------------------------------</span><span class="er">|</span></span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="er">|</span> PNet  <span class="sc">|</span> <span class="er">~</span><span class="dv">12</span>×<span class="dv">12</span><span class="sc">+</span>        <span class="er">|</span> <span class="er">~</span><span class="dv">3</span>k        <span class="sc">|</span> <span class="dv">30</span> kB     <span class="sc">|</span> <span class="dv">2</span><span class="sc">-</span>class face prob <span class="sc">+</span> bbox reg  <span class="sc">|</span> Fully conv, sliding window stage  <span class="sc">|</span></span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="er">|</span> RNet  <span class="sc">|</span> <span class="dv">24</span>×<span class="dv">24</span>          <span class="sc">|</span> <span class="er">~</span><span class="dv">30</span>k       <span class="sc">|</span> <span class="dv">400</span> kB    <span class="sc">|</span> <span class="dv">2</span><span class="sc">-</span>class face prob <span class="sc">+</span> bbox reg  <span class="sc">|</span> Dense layers, higher recall       <span class="sc">|</span></span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="er">|</span> ONet  <span class="sc">|</span> <span class="dv">48</span>×<span class="dv">48</span>          <span class="sc">|</span> <span class="er">~</span><span class="dv">100</span>k      <span class="sc">|</span> <span class="dv">2</span> MB      <span class="sc">|</span> <span class="dv">2</span><span class="sc">-</span>class prob <span class="sc">+</span> bbox <span class="sc">+</span> <span class="dv">5</span><span class="sc">-</span>point <span class="sc">|</span> Landmark detection stage          <span class="sc">|</span></span></code></pre><p></p></div>
<p>Inception-ResNet-v1 is a convolutional neural network architecture combining Inception modules
with residual connections, designed for face recognition tasks. The model achieves high accuracy
on standard face verification benchmarks such as LFW (Labeled Faces in the Wild).</p>
</div>

<div class="section">
<h3 id="model-variants-and-performance-lfw-accuracy-">Model Variants and Performance (LFW accuracy)<a class="anchor" aria-label="anchor" href="#model-variants-and-performance-lfw-accuracy-"></a></h3>


<p></p><div class="sourceCode"><pre><code><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="sc">|</span>    Weights     <span class="sc">|</span> LFW Accuracy <span class="sc">|</span> File Size <span class="sc">|</span></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="er">|</span><span class="sc">----------------</span><span class="er">|</span><span class="sc">--------------</span><span class="er">|</span><span class="sc">-----------</span><span class="er">|</span></span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="er">|</span> CASIA<span class="sc">-</span>Webface  <span class="sc">|</span> <span class="fl">99.05</span>%       <span class="sc">|</span> <span class="dv">111</span> MB    <span class="sc">|</span></span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="er">|</span> VGGFace2       <span class="sc">|</span> <span class="fl">99.65</span>%       <span class="sc">|</span> <span class="dv">107</span> MB    <span class="sc">|</span></span></code></pre><p></p></div><ul><li><p>The CASIA-Webface pretrained weights provide strong baseline accuracy.</p></li>
<li><p>The VGGFace2 pretrained weights achieve higher accuracy, benefiting from a larger, more diverse dataset.</p></li>
</ul></div>

    </div>
    <div id="functions">
    <h2>Functions</h2>

<ul><li><p><code>model_facenet_pnet()</code>: PNet (Proposal Network) — small fully-convolutional network for candidate face box generation.</p></li>
<li><p><code>model_facenet_rnet()</code>: RNet (Refine Network) — medium CNN with dense layers for refining and rejecting false positives.</p></li>
<li><p><code>model_facenet_onet()</code>: ONet (Output Network) — deeper CNN that outputs final bounding boxes and 5 facial landmark points.</p></li>
<li><p><code>model_mtcnn()</code>: MTCNN (Multi-task Cascaded Convolutional Networks) — face detection and alignment using a cascade of three neural networks</p></li>
<li><p><code>model_facenet_inception_resnet_v1()</code>: Inception-ResNet-v1 — high-accuracy face recognition model combining Inception modules with residual connections, pretrained on VGGFace2 and CASIA-Webface datasets</p></li>
</ul></div>
    <div id="see-also">
    <h2>See also</h2>
    <div class="dont-index"><p>Other object_detection_model:
<code><a href="model_convnext_detection.html">model_convnext_detection</a></code>,
<code><a href="model_fasterrcnn.html">model_fasterrcnn</a></code></p>
<p>Other object_detection_model:
<code><a href="model_convnext_detection.html">model_convnext_detection</a></code>,
<code><a href="model_fasterrcnn.html">model_fasterrcnn</a></code></p>
<p>Other classification_model:
<code><a href="model_alexnet.html">model_alexnet()</a></code>,
<code><a href="model_convnext.html">model_convnext</a></code>,
<code><a href="model_efficientnet.html">model_efficientnet</a></code>,
<code><a href="model_efficientnet_v2.html">model_efficientnet_v2</a></code>,
<code><a href="model_inception_v3.html">model_inception_v3()</a></code>,
<code><a href="model_maxvit.html">model_maxvit()</a></code>,
<code><a href="model_mobilenet_v2.html">model_mobilenet_v2()</a></code>,
<code><a href="model_mobilenet_v3.html">model_mobilenet_v3</a></code>,
<code><a href="model_resnet.html">model_resnet</a></code>,
<code><a href="model_vgg.html">model_vgg</a></code>,
<code><a href="model_vit.html">model_vit</a></code></p></div>
    </div>

    <div id="ref-examples">
    <h2>Examples</h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span><span class="kw">if</span> <span class="op">(</span><span class="cn">FALSE</span><span class="op">)</span> <span class="op">{</span> <span class="co"># \dontrun{</span></span></span>
<span class="r-in"><span><span class="co"># Example usage of PNet</span></span></span>
<span class="r-in"><span><span class="va">model_pnet</span> <span class="op">&lt;-</span> <span class="fu">model_facenet_pnet</span><span class="op">(</span>pretrained <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">model_pnet</span><span class="op">$</span><span class="fu">eval</span><span class="op">(</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">input_pnet</span> <span class="op">&lt;-</span> <span class="fu">torch_randn</span><span class="op">(</span><span class="fl">1</span>, <span class="fl">3</span>, <span class="fl">224</span>, <span class="fl">224</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">output_pnet</span> <span class="op">&lt;-</span> <span class="fu">model_pnet</span><span class="op">(</span><span class="va">input_pnet</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">output_pnet</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Example usage of RNet</span></span></span>
<span class="r-in"><span><span class="va">model_rnet</span> <span class="op">&lt;-</span> <span class="fu">model_facenet_rnet</span><span class="op">(</span>pretrained <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">model_rnet</span><span class="op">$</span><span class="fu">eval</span><span class="op">(</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">input_rnet</span> <span class="op">&lt;-</span> <span class="fu">torch_randn</span><span class="op">(</span><span class="fl">1</span>, <span class="fl">3</span>, <span class="fl">24</span>, <span class="fl">24</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">output_rnet</span> <span class="op">&lt;-</span> <span class="fu">model_rnet</span><span class="op">(</span><span class="va">input_rnet</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">output_rnet</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Example usage of ONet</span></span></span>
<span class="r-in"><span><span class="va">model_onet</span> <span class="op">&lt;-</span> <span class="fu">model_facenet_onet</span><span class="op">(</span>pretrained <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">model_onet</span><span class="op">$</span><span class="fu">eval</span><span class="op">(</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">input_onet</span> <span class="op">&lt;-</span> <span class="fu">torch_randn</span><span class="op">(</span><span class="fl">1</span>, <span class="fl">3</span>, <span class="fl">48</span>, <span class="fl">48</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">output_onet</span> <span class="op">&lt;-</span> <span class="fu">model_onet</span><span class="op">(</span><span class="va">input_onet</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">output_onet</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Example usage of MTCNN</span></span></span>
<span class="r-in"><span><span class="va">mtcnn</span> <span class="op">&lt;-</span> <span class="fu">model_mtcnn</span><span class="op">(</span>pretrained <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">mtcnn</span><span class="op">$</span><span class="fu">eval</span><span class="op">(</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">image_tensor</span> <span class="op">&lt;-</span> <span class="fu">torch_randn</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">3</span>, <span class="fl">224</span>, <span class="fl">224</span><span class="op">)</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">out</span> <span class="op">&lt;-</span> <span class="fu">mtcnn</span><span class="op">(</span><span class="va">image_tensor</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">out</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Load an image from the web</span></span></span>
<span class="r-in"><span><span class="va">wmc</span> <span class="op">&lt;-</span> <span class="st">"https://upload.wikimedia.org/wikipedia/commons/"</span></span></span>
<span class="r-in"><span><span class="va">url</span> <span class="op">&lt;-</span> <span class="st">"b/b4/Catherine_Bell_200101233d_hr_%28cropped%29.jpg"</span></span></span>
<span class="r-in"><span><span class="va">img</span> <span class="op">&lt;-</span> <span class="fu"><a href="base_loader.html">base_loader</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="va">wmc</span>,<span class="va">url</span><span class="op">)</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Convert to torch tensor [C, H, W] normalized</span></span></span>
<span class="r-in"><span><span class="va">input</span> <span class="op">&lt;-</span> <span class="fu"><a href="transform_to_tensor.html">transform_to_tensor</a></span><span class="op">(</span><span class="va">img</span><span class="op">)</span>  <span class="co"># [C, H, W]</span></span></span>
<span class="r-in"><span><span class="va">batch</span> <span class="op">&lt;-</span> <span class="va">input</span><span class="op">$</span><span class="fu">unsqueeze</span><span class="op">(</span><span class="fl">1</span><span class="op">)</span>   <span class="co"># [1, C, H, W]</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Load pretrained model</span></span></span>
<span class="r-in"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu">model_facenet_inception_resnet_v1</span><span class="op">(</span>pretrained <span class="op">=</span> <span class="st">"vggface2"</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">model</span><span class="op">$</span><span class="fu">eval</span><span class="op">(</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">output</span> <span class="op">&lt;-</span> <span class="fu">model</span><span class="op">(</span><span class="va">batch</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">output</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Example usage of Inception-ResNet-v1 with CASIA-Webface Weights</span></span></span>
<span class="r-in"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu">model_facenet_inception_resnet_v1</span><span class="op">(</span>pretrained <span class="op">=</span> <span class="st">"casia-webface"</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">model</span><span class="op">$</span><span class="fu">eval</span><span class="op">(</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">output</span> <span class="op">&lt;-</span> <span class="fu">model</span><span class="op">(</span><span class="va">batch</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">output</span></span></span>
<span class="r-in"><span><span class="op">}</span> <span class="co"># }</span></span></span>
<span class="r-in"><span></span></span>
</code></pre></div>
    </div>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <nav id="toc" data-toggle="toc" class="sticky-top"><h2 data-toc-skip>Contents</h2>
    </nav></div>
</div>


      <footer><div class="copyright">
  <p></p><p>Developed by Daniel Falbel.</p>
</div>

<div class="pkgdown">
  <p></p><p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.2.0.</p>
</div>

      </footer></div>






  </body></html>


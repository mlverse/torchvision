<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Vision Transformer Implementation — model_vit • torchvision</title><!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.1/jquery.min.js" integrity="sha512-v2CJ7UaYy4JwqLDIrZUI/4hqeoQieOmAZNXBeQyjo21dadnwR+8ZaIJVT8EE2iyI61OV8e6M8PP2/4hpQINQ/g==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/united/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous"><script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css"><script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous"><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet"><script src="../pkgdown.js"></script><meta property="og:title" content="Vision Transformer Implementation — model_vit"><meta property="og:description" content="Vision Transformer (ViT) models implement the architecture proposed in the paper
An Image is Worth 16x16 Words.
These models are designed for image classification tasks and operate by treating
image patches as tokens in a Transformer model."><meta name="robots" content="noindex"><!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--><!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=G-HD24T4Z9Z3"></script><script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-HD24T4Z9Z3');
</script></head><body data-spy="scroll" data-target="#toc">


    <div class="container template-reference-topic">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">torchvision</a>
        <span class="version label label-danger" data-toggle="tooltip" data-placement="bottom" title="In-development version">0.8.0.9000</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav"><li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Examples

    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu"><li>
      <a href="../articles/examples/mnist-mlp.html">mnist-mlp</a>
    </li>
    <li>
      <a href="../articles/examples/mnist-cnn.html">mnist-cnn</a>
    </li>
    <li>
      <a href="../articles/examples/mnist-dcgan.html">mnist-dcgan</a>
    </li>
    <li>
      <a href="../articles/examples/tinyimagenet-alexnet.html">tinyimagenet-alexnet</a>
    </li>
    <li>
      <a href="../articles/examples/style-transfer.html">style-transfer</a>
    </li>
    <li>
      <a href="../articles/examples/texture-nca.html">texture-nca</a>
    </li>
    <li>
      <a href="../articles/examples/fcnresnet.html">fcnresnet</a>
    </li>
  </ul></li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul><ul class="nav navbar-nav navbar-right"><li>
  <a href="https://github.com/mlverse/torchvision/" class="external-link">
    <span class="fab fa-github fa-lg"></span>

  </a>
</li>
      </ul></div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->



      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Vision Transformer Implementation</h1>
    <small class="dont-index">Source: <a href="https://github.com/mlverse/torchvision/blob/main/R/models-vit.R" class="external-link"><code>R/models-vit.R</code></a></small>
    <div class="hidden name"><code>model_vit.Rd</code></div>
    </div>

    <div class="ref-description">
    <p>Vision Transformer (ViT) models implement the architecture proposed in the paper
<a href="https://arxiv.org/abs/2010.11929" class="external-link">An Image is Worth 16x16 Words</a>.
These models are designed for image classification tasks and operate by treating
image patches as tokens in a Transformer model.</p>
    </div>

    <div id="ref-usage">
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">model_vit_b_16</span><span class="op">(</span>pretrained <span class="op">=</span> <span class="cn">FALSE</span>, progress <span class="op">=</span> <span class="cn">TRUE</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">model_vit_b_32</span><span class="op">(</span>pretrained <span class="op">=</span> <span class="cn">FALSE</span>, progress <span class="op">=</span> <span class="cn">TRUE</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">model_vit_l_16</span><span class="op">(</span>pretrained <span class="op">=</span> <span class="cn">FALSE</span>, progress <span class="op">=</span> <span class="cn">TRUE</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">model_vit_l_32</span><span class="op">(</span>pretrained <span class="op">=</span> <span class="cn">FALSE</span>, progress <span class="op">=</span> <span class="cn">TRUE</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">model_vit_h_14</span><span class="op">(</span>pretrained <span class="op">=</span> <span class="cn">FALSE</span>, progress <span class="op">=</span> <span class="cn">TRUE</span>, <span class="va">...</span><span class="op">)</span></span></code></pre></div>
    </div>

    <div id="arguments">
    <h2>Arguments</h2>


<dl><dt id="arg-pretrained">pretrained<a class="anchor" aria-label="anchor" href="#arg-pretrained"></a></dt>
<dd><p>(bool): If TRUE, returns a model pre-trained on ImageNet.</p></dd>


<dt id="arg-progress">progress<a class="anchor" aria-label="anchor" href="#arg-progress"></a></dt>
<dd><p>(bool): If TRUE, displays a progress bar of the download to
stderr.</p></dd>


<dt id="arg--">...<a class="anchor" aria-label="anchor" href="#arg--"></a></dt>
<dd><p>Other parameters passed to the model implementation.</p></dd>

</dl></div>
    <div id="details">
    <h2>Details</h2>

<div class="section">
<h3 id="model-variants-and-performance-imagenet-k-">Model Variants and Performance (ImageNet-1k)<a class="anchor" aria-label="anchor" href="#model-variants-and-performance-imagenet-k-"></a></h3>


<p></p><div class="sourceCode"><pre><code><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="sc">|</span> Model     <span class="sc">|</span> Top<span class="dv">-1</span> Acc <span class="sc">|</span> Top<span class="dv">-5</span> Acc <span class="sc">|</span> Params  <span class="sc">|</span> GFLOPS <span class="sc">|</span> File Size <span class="sc">|</span> Weights Used              <span class="sc">|</span> Notes                  <span class="sc">|</span></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="er">|</span><span class="sc">-----------</span><span class="er">|</span><span class="sc">-----------</span><span class="er">|</span><span class="sc">-----------</span><span class="er">|</span><span class="sc">---------</span><span class="er">|</span><span class="sc">--------</span><span class="er">|</span><span class="sc">-----------</span><span class="er">|</span><span class="sc">---------------------------</span><span class="er">|</span><span class="sc">------------------------</span><span class="er">|</span></span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="er">|</span> vit_b_16  <span class="sc">|</span> <span class="fl">81.1</span><span class="sc">%     | 95.3%</span>     <span class="er">|</span> <span class="fl">86.6</span>M   <span class="sc">|</span> <span class="fl">17.56</span>  <span class="sc">|</span> <span class="dv">346</span> MB    <span class="sc">|</span> IMAGENET1K_V1             <span class="sc">|</span> Base, <span class="dv">16</span>x16 patches    <span class="sc">|</span></span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="er">|</span> vit_b_32  <span class="sc">|</span> <span class="fl">75.9</span><span class="sc">%     | 92.5%</span>     <span class="er">|</span> <span class="fl">88.2</span>M   <span class="sc">|</span> <span class="fl">4.41</span>   <span class="sc">|</span> <span class="dv">353</span> MB    <span class="sc">|</span> IMAGENET1K_V1             <span class="sc">|</span> Base, <span class="dv">32</span>x32 patches    <span class="sc">|</span></span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="er">|</span> vit_l_16  <span class="sc">|</span> <span class="fl">79.7</span><span class="sc">%     | 94.6%</span>     <span class="er">|</span> <span class="fl">304.3</span>M  <span class="sc">|</span> <span class="fl">61.55</span>  <span class="sc">|</span> <span class="fl">1.22</span> GB   <span class="sc">|</span> IMAGENET1K_V1             <span class="sc">|</span> Large, <span class="dv">16</span>x16 patches   <span class="sc">|</span></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="er">|</span> vit_l_32  <span class="sc">|</span> <span class="fl">77.0</span><span class="sc">%     | 93.1%</span>     <span class="er">|</span> <span class="fl">306.5</span>M  <span class="sc">|</span> <span class="fl">15.38</span>  <span class="sc">|</span> <span class="fl">1.23</span> GB   <span class="sc">|</span> IMAGENET1K_V1             <span class="sc">|</span> Large, <span class="dv">32</span>x32 patches   <span class="sc">|</span></span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a><span class="er">|</span> vit_h_14  <span class="sc">|</span> <span class="fl">88.6</span><span class="sc">%     | 98.7%</span>     <span class="er">|</span> <span class="fl">633.5</span>M  <span class="sc">|</span> <span class="fl">1016.7</span> <span class="sc">|</span> <span class="fl">2.53</span> GB   <span class="sc">|</span> IMAGENET1K_SWAG_E2E_V1    <span class="sc">|</span> Huge, <span class="dv">14</span>x14 patches    <span class="sc">|</span></span></code></pre><p></p></div><ul><li><p><strong>TorchVision Recipe</strong>: <a href="https://github.com/pytorch/vision/tree/main/references/classification" class="external-link">https://github.com/pytorch/vision/tree/main/references/classification</a></p></li>
<li><p><strong>SWAG Recipe</strong>: <a href="https://github.com/facebookresearch/SWAG" class="external-link">https://github.com/facebookresearch/SWAG</a></p></li>
</ul><p><strong>Weights Selection</strong>:</p><ul><li><p>All models use the default <code>IMAGENET1K_V1</code> weights for consistency, stability, and official support from TorchVision.</p></li>
<li><p>These are supervised weights trained on ImageNet-1k.</p></li>
<li><p>For <code>vit_h_14</code>, the default weight is <code>IMAGENET1K_SWAG_E2E_V1</code>, pretrained on SWAG and fine-tuned on ImageNet.</p></li>
</ul></div>

    </div>
    <div id="functions">
    <h2>Functions</h2>

<ul><li><p><code>model_vit_b_16()</code>: ViT-B/16 model (Base, 16×16 patch size)</p></li>
<li><p><code>model_vit_b_32()</code>: ViT-B/32 model (Base, 32×32 patch size)</p></li>
<li><p><code>model_vit_l_16()</code>: ViT-L/16 model (Base, 16×16 patch size)</p></li>
<li><p><code>model_vit_l_32()</code>: ViT-L/32 model (Base, 32×32 patch size)</p></li>
<li><p><code>model_vit_h_14()</code>: ViT-H/14 model (Base, 14×14 patch size)</p></li>
</ul></div>
    <div id="see-also">
    <h2>See also</h2>
    <div class="dont-index"><p>Other classification_model:
<code><a href="model_alexnet.html">model_alexnet()</a></code>,
<code><a href="model_convnext.html">model_convnext</a></code>,
<code><a href="model_efficientnet.html">model_efficientnet</a></code>,
<code><a href="model_efficientnet_v2.html">model_efficientnet_v2</a></code>,
<code><a href="model_facenet.html">model_facenet</a></code>,
<code><a href="model_inception_v3.html">model_inception_v3()</a></code>,
<code><a href="model_maxvit.html">model_maxvit()</a></code>,
<code><a href="model_mobilenet_v2.html">model_mobilenet_v2()</a></code>,
<code><a href="model_mobilenet_v3.html">model_mobilenet_v3</a></code>,
<code><a href="model_resnet.html">model_resnet</a></code>,
<code><a href="model_vgg.html">model_vgg</a></code></p></div>
    </div>

  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <nav id="toc" data-toggle="toc" class="sticky-top"><h2 data-toc-skip>Contents</h2>
    </nav></div>
</div>


      <footer><div class="copyright">
  <p></p><p>Developed by Daniel Falbel.</p>
</div>

<div class="pkgdown">
  <p></p><p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.2.0.</p>
</div>

      </footer></div>






  </body></html>


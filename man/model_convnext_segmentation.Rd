% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/models-convnext_segmentation.R
\name{model_convnext_segmentation}
\alias{model_convnext_segmentation}
\alias{model_convnext_tiny_fcn}
\alias{model_convnext_small_fcn}
\alias{model_convnext_base_fcn}
\alias{model_convnext_tiny_upernet}
\alias{model_convnext_small_upernet}
\alias{model_convnext_base_upernet}
\title{ConvNeXt Segmentation Models}
\usage{
model_convnext_tiny_fcn(
  num_classes = 21,
  aux_loss = FALSE,
  pretrained_backbone = FALSE,
  ...
)

model_convnext_small_fcn(
  num_classes = 21,
  aux_loss = FALSE,
  pretrained_backbone = FALSE,
  ...
)

model_convnext_base_fcn(
  num_classes = 21,
  aux_loss = FALSE,
  pretrained_backbone = FALSE,
  ...
)

model_convnext_tiny_upernet(
  num_classes = 21,
  aux_loss = FALSE,
  pretrained_backbone = FALSE,
  pool_scales = c(1, 2, 3, 6),
  ...
)

model_convnext_small_upernet(
  num_classes = 21,
  aux_loss = FALSE,
  pretrained_backbone = FALSE,
  pool_scales = c(1, 2, 3, 6),
  ...
)

model_convnext_base_upernet(
  num_classes = 21,
  aux_loss = FALSE,
  pretrained_backbone = FALSE,
  pool_scales = c(1, 2, 3, 6),
  ...
)
}
\arguments{
\item{num_classes}{Number of output segmentation classes. Default: 21 (PASCAL VOC).}

\item{aux_loss}{Logical. If TRUE, includes an auxiliary classifier branch.
Default: FALSE.}

\item{pretrained_backbone}{Logical. If TRUE, loads ImageNet pretrained

weights for the ConvNeXt backbone. Default: FALSE.}

\item{...}{Additional arguments passed to the backbone.}

\item{pool_scales}{Numeric vector. Pooling scales used in the Pyramid Pooling
Module for UPerNet models. Default: c(1, 2, 3, 6).}
}
\value{
An \code{nn_module} representing the segmentation model.
}
\description{
Semantic segmentation models that use a ConvNeXt backbone with either
an FCN (Fully Convolutional Network) head or a UPerNet (Unified Perceptual
Parsing Network) head.

These models follow the architecture patterns from mmsegmentation and
can be used for semantic segmentation tasks.
}
\section{Functions}{
\itemize{
\item \code{model_convnext_tiny_fcn()}: ConvNeXt Tiny with FCN head

\item \code{model_convnext_small_fcn()}: ConvNeXt Small with FCN head

\item \code{model_convnext_base_fcn()}: ConvNeXt Base with FCN head

\item \code{model_convnext_tiny_upernet()}: ConvNeXt Tiny with UPerNet head

\item \code{model_convnext_small_upernet()}: ConvNeXt Small with UPerNet head

\item \code{model_convnext_base_upernet()}: ConvNeXt Base with UPerNet head

}}
\section{Available FCN Models}{

\itemize{
\item \code{model_convnext_tiny_fcn()}
\item \code{model_convnext_small_fcn()}
\item \code{model_convnext_base_fcn()}
}
}

\section{Available UPerNet Models}{

\itemize{
\item \code{model_convnext_tiny_upernet()}
\item \code{model_convnext_small_upernet()}
\item \code{model_convnext_base_upernet()}
}
}

\examples{
\dontrun{
library(magrittr)
norm_mean <- c(0.485, 0.456, 0.406) # ImageNet normalization constants
norm_std  <- c(0.229, 0.224, 0.225)

# Use a publicly available image
wmc <- "https://upload.wikimedia.org/wikipedia/commons/thumb/"
url <- "e/ea/Morsan_Normande_vache.jpg/120px-Morsan_Normande_vache.jpg"
img <- base_loader(paste0(wmc, url))

input <- img \%>\%
  transform_to_tensor() \%>\%
  transform_resize(c(520, 520)) \%>\%
  transform_normalize(norm_mean, norm_std)
batch <- input$unsqueeze(1)

# ConvNeXt Tiny FCN segmentation
model <- model_convnext_tiny_fcn(num_classes = 21, pretrained_backbone = TRUE)
model$eval()
output <- model(batch)

# Visualize result
segmented <- draw_segmentation_masks(input, output$out$squeeze(1))
tensor_image_display(segmented)

# ConvNeXt Tiny UPerNet segmentation
model <- model_convnext_tiny_upernet(num_classes = 21, pretrained_backbone = TRUE)
model$eval()
output <- model(batch)

# Visualize result
segmented <- draw_segmentation_masks(input, output$out$squeeze(1))
tensor_image_display(segmented)
}

}
\seealso{
Other semantic_segmentation_model: 
\code{\link{model_deeplabv3}},
\code{\link{model_fcn_resnet}}
}
\concept{semantic_segmentation_model}

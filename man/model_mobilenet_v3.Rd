% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/models-mobilenetv3.R
\name{model_mobilenet_v3}
\alias{model_mobilenet_v3}
\alias{model_mobilenet_v3_large}
\alias{model_mobilenet_v3_small}
\title{MobileNetV3 Implementation in R Torch}
\usage{
model_mobilenet_v3_large(
  pretrained = FALSE,
  progress = TRUE,
  num_classes = 1000,
  width_mult = 1
)

model_mobilenet_v3_small(
  pretrained = FALSE,
  progress = TRUE,
  num_classes = 1000,
  width_mult = 1
)
}
\arguments{
\item{pretrained}{(bool): If TRUE, returns a model pre-trained on ImageNet.}

\item{progress}{(bool): If TRUE, displays a progress bar of the download to
stderr.}

\item{num_classes}{number of output classes (default: 1000).}

\item{width_mult}{width multiplier for model scaling (default: 1.0).}
}
\description{
MobileNetV3 is a state-of-the-art lightweight convolutional neural network architecture
designed for mobile and embedded vision applications. This implementation follows the
design and optimizations presented in the original paper:\href{https://arxiv.org/abs/1905.02244}{MobileNetV3: Searching for MobileNetV3}
}
\details{
The model includes two variants:
\itemize{
\item \code{model_mobilenet_v3_large()}
\item \code{model_mobilenet_v3_small()}
}

Both variants utilize efficient blocks such as inverted residuals, squeeze-and-excitation (SE) modules,
and hard-swish activations for improved accuracy and efficiency.
\subsection{Model Summary and Performance for pretrained weights}{

\if{html}{\out{<div class="sourceCode">}}\preformatted{| Model                  | Top-1 Acc | Top-5 Acc | Params  | GFLOPS | File Size | Notes                               |
|------------------------|-----------|-----------|---------|--------|-----------|-------------------------------------|
| MobileNetV3 Large      | 74.04\%    | 91.34\%    | 5.48M   | 0.22   | 21.1 MB   | Trained from scratch, simple recipe |
| MobileNetV3 Small      | 67.67\%    | 87.40\%    | 2.54M   | 0.06   | 9.8 MB    | Improved recipe over original paper |
}\if{html}{\out{</div>}}
}
}
\section{Functions}{
\itemize{
\item \code{model_mobilenet_v3_large()}: MobileNetV3 Large model with about 5.5 million parameters.

\item \code{model_mobilenet_v3_small()}: MobileNetV3 Small model with about 2.5 million parameters.

}}
\examples{
\dontrun{
# 1. Download sample image (dog)
img_path <- download_and_cache("https://raw.githubusercontent.com/pytorch/hub/master/dog.jpg")
img <- jpeg::readJPEG(img_path)

# 2. Convert to tensor (RGB only)
input <- torch_tensor(aperm(img[,,1:3], c(3,1,2)), dtype = torch_float())

# 3. Resize to 224x224
input <- nnf_interpolate(
  input$unsqueeze(1), size = c(224,224),
  mode = "bilinear", align_corners = FALSE
)$squeeze(1)

# 4. Normalize with ImageNet mean/std
mean <- torch_tensor(c(0.485, 0.456, 0.406))$view(c(3,1,1))
std  <- torch_tensor(c(0.229, 0.224, 0.225))$view(c(3,1,1))
input <- (input - mean) / std

# 5. Add batch dimension
input <- input$unsqueeze(1)  # shape [1,3,224,224]

# 6. Load pretrained models
model_large <- model_mobilenet_v3_large(pretrained = TRUE)
model_small <- model_mobilenet_v3_small(pretrained = TRUE)
model_large$eval()
model_small$eval()

# 7. Forward pass
output_l <- model_large(input)
output_s <- model_small(input)

# 8. Load ImageNet class labels
labels_path <- download_and_cache("https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt")
classes <- readLines(labels_path)

# 9. Top-5 printing helper
print_top5 <- function(output, classes, title) {
  topk <- output$topk(k = 5)
  idxs <- as.integer(topk[[2]])
  scores <- as.numeric(topk[[1]])
  cat("\n", title, "\n", sep = "")
  for (i in seq_along(idxs)) {
    cat(sprintf("\%d. \%s (\%.2f)\n", i, classes[idxs[i] + 1], scores[i]))
  }
}

# 10. Print predictions
print_top5(output_l, classes, "MobileNetV3 Large Top-5 Predictions:")
print_top5(output_s, classes, "MobileNetV3 Small Top-5 Predictions:")
}

}
\seealso{
Other models: 
\code{\link{model_alexnet}()},
\code{\link{model_deeplabv3}},
\code{\link{model_efficientnet}},
\code{\link{model_efficientnet_v2}},
\code{\link{model_facenet}},
\code{\link{model_fcn_resnet}},
\code{\link{model_inception_v3}()},
\code{\link{model_maxvit}()},
\code{\link{model_mobilenet_v2}()},
\code{\link{model_resnet}},
\code{\link{model_vgg}},
\code{\link{model_vit}}
}
\concept{models}

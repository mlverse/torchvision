% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/dataset-cityscapes.R
\name{cityscapes_dataset}
\alias{cityscapes_dataset}
\title{Cityscapes Dataset for Instance and Semantic Segmentation}
\usage{
cityscapes_dataset(
  root = tempdir(),
  split = "train",
  mode = "fine",
  target_type = "instance",
  transform = NULL,
  target_transform = NULL
)
}
\arguments{
\item{root}{Character. Root directory where dataset is stored (default: \code{tempdir()}).}

\item{split}{Character. One of "train", "val", or "test" (default: "train").}

\item{mode}{Character. Annotation quality: "fine" for high-quality dense annotations
or "coarse" for weaker annotations (default: "fine").}

\item{target_type}{Character vector. Types of annotations to load. Can include:
\itemize{
\item "instance": Instance segmentation masks (each object has unique ID)
\item "semantic": Semantic segmentation masks (class IDs only)
\item "polygon": Polygon annotations in JSON format
\item "color": Color-coded visualization of annotations
}
Multiple types can be specified (default: "instance").}

\item{transform}{Function to transform the input image (default: NULL).}

\item{target_transform}{Function to transform the target annotations (default: NULL).}
}
\value{
A torch dataset object. Each item is a named list:
\itemize{
\item \code{x}: RGB image array of shape (H, W, 3) or transformed tensor
\item \code{y}: Named list containing requested target types:
\itemize{
\item \code{instance}: Instance segmentation mask (H, W) with unique IDs per object
\item \code{semantic}: Semantic segmentation mask (H, W) with class IDs
\item \code{color}: Color-coded visualization (H, W, 3)
\item \code{polygon}: Polygon annotations (nested list structure)
}
}
}
\description{
The Cityscapes dataset contains street scene images from 50 European cities
with pixel-level annotations for semantic and instance segmentation tasks.
This dataset is widely used for urban scene understanding research.
}
\section{Dataset Structure}{

The Cityscapes dataset includes:
\itemize{
\item 5,000 finely annotated images (2,975 train, 500 val, 1,525 test)
\item 20,000 coarsely annotated images
\item 19 semantic classes for urban scenes
\item Dense pixel-level annotations at 1024x2048 resolution
\item Images from 50 different European cities
}
}

\section{Semantic Classes}{

The dataset includes 19 evaluation classes:
road, sidewalk, building, wall, fence, pole, traffic light, traffic sign,
vegetation, terrain, sky, person, rider, car, truck, bus, train, motorcycle,
bicycle.
}

\section{Download}{

Cityscapes requires manual download and registration:
\enumerate{
\item Register at \url{https://www.cityscapes-dataset.com/}
\item Download packages:
\itemize{
\item leftImg8bit_trainvaltest.zip (11GB) - RGB images
\item gtFine_trainvaltest.zip (241MB) - Fine annotations
\item gtCoarse.zip (1.3GB) - Coarse annotations (optional)
}
\item Extract to root directory
}

Expected directory structure:
\preformatted{
root/
├── leftImg8bit/
│   ├── train/
│   ├── val/
│   └── test/
├── gtFine/
│   ├── train/
│   ├── val/
│   └── test/
└── gtCoarse/
    ├── train/
    ├── train_extra/
    └── val/
}
}

\section{Integration with draw_segmentation_masks}{

The output is directly compatible with \code{\link{draw_segmentation_masks}}:
\preformatted{
item <- dataset[1]
# For instance segmentation
overlay <- draw_segmentation_masks(item$x, item$y$instance > 0)
# For semantic segmentation
overlay <- draw_segmentation_masks(item$x, item$y$semantic == class_id)
}
}

\examples{
\dontrun{
# Load Cityscapes with instance segmentation
cityscapes_train <- cityscapes_dataset(
  root = "~/datasets/cityscapes",
  split = "train",
  mode = "fine",
  target_type = "instance",
  transform = transform_to_tensor
)

# Get first item
first <- cityscapes_train[1]
first$x  # Image tensor (3, H, W)
first$y$instance  # Instance mask (H, W)

# Visualize with draw_segmentation_masks
# Create boolean mask for all instances
mask <- first$y$instance > 0
overlay <- draw_segmentation_masks(first$x, mask$unsqueeze(1), alpha = 0.5)
tensor_image_browse(overlay)

# Load with multiple target types
cityscapes_multi <- cityscapes_dataset(
  root = "~/datasets/cityscapes",
  split = "val",
  mode = "fine",
  target_type = c("instance", "semantic"),
  transform = transform_to_tensor
)

item <- cityscapes_multi[1]
# Semantic mask for specific class (e.g., cars = class 13)
car_mask <- item$y$semantic == 13
overlay <- draw_segmentation_masks(item$x, car_mask$unsqueeze(1))
tensor_image_browse(overlay)

# Use with dataloader
dl <- torch::dataloader(cityscapes_train, batch_size = 4, shuffle = TRUE)
batch <- dl$.iter()$.next()
}

}
\seealso{
Other segmentation_dataset: 
\code{\link{oxfordiiitpet_segmentation_dataset}()},
\code{\link{pascal_voc_datasets}},
\code{\link{rf100_peixos_segmentation_dataset}()}
}
\concept{segmentation_dataset}
